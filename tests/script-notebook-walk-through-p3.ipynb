{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a767eb8",
   "metadata": {},
   "source": [
    "# This Notebook provides the walk through each step for single sleep-EEG (\".edf\") file to present some details about possible the package in details - Part3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54169d9f",
   "metadata": {},
   "source": [
    "The whole notebooks parts should be run together inorder to explain the first each note-books are provided seperately.\n",
    "This will help the user to identify the any-issues while first time running the package.\n",
    "\n",
    "However these parts include the first part and wanted functions in the first block.\n",
    "So the user can run the first block as whole to finish the previous parts and check the next stages.\n",
    "\n",
    "If the user want to run the whole script together pleace check the last-note-book."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6d678d",
   "metadata": {},
   "source": [
    "## Upto part-2 and needed modules\n",
    "\n",
    "Since you are using the script to run the file, please load the latest .whl file \n",
    "located in the \"EEG_PSG_loose_lead_test/dist/sleep_EEG_loose_lead_detect-0.0-py3-none-any.whl\"\n",
    "\n",
    "Once the package is dowloaded, then change the directory via the command in cmd-prompt\n",
    "\n",
    "cd .../EEG_PSG_loose_lead_test/dist/\n",
    "\n",
    "Then install the packge via the pip command via the command in cmd-prompt,\n",
    "\n",
    "pip install sleep_EEG_loose_lead_detect-0.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac903c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "# from multiprocessing import Pool#, TimeoutError\n",
    "\n",
    "import sleep_EEG_loose_lead_detect as sleep_EEG_loose_lead_detect\n",
    "# --------------------------------------------------------------------------\n",
    "# load package functions\n",
    "# assign the working directory of the package\n",
    "# --------------------------------------------------------------------------\n",
    "from sleep_EEG_loose_lead_detect.directory_utils import EEG_sleep_dir\n",
    "\n",
    "from sleep_EEG_loose_lead_detect.optional_parameters import parameter_assignment\n",
    "\n",
    "#checking only one get_root_channels function whether the loading suceeds\n",
    "# # here non-normlaised EEG is obtained in the preproceeing step in time domain\n",
    "from sleep_EEG_loose_lead_detect.preprocessing.load_EDF_dataset_events import load_root_dataset\n",
    "from sleep_EEG_loose_lead_detect.preprocessing.find_bad_epochs import markBadEpochs\n",
    "from sleep_EEG_loose_lead_detect.preprocessing.segment_filter_EEG import segment_EEG\n",
    "from sleep_EEG_loose_lead_detect.preprocessing.cont_segs_of_whole_EEG import save_cont_segs, continious_seg_to_np\n",
    "# --------------------------------------------------------------------------\n",
    "# spindle retaleed function based on YASA\n",
    "# --------------------------------------------------------------------------\n",
    "from sleep_EEG_loose_lead_detect.preprocessing.spindle_fun import spindle_detect_main\n",
    "from sleep_EEG_loose_lead_detect.preprocessing.detected_spindle_one_hot import convert_to_full_one_hot_mapping_based_cont_seg_sp_sw_all_channels\n",
    "\n",
    "\n",
    "from sleep_EEG_loose_lead_detect.loose_lead_events.events_to_txt import preprocess_events_to_txt\n",
    "\n",
    "from sleep_EEG_loose_lead_detect.channel_correlation_outlier.correlation_functions import MT_based_correltion_calc_in_continious_segs\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "logger = logging.getLogger(\"sleep_loose_lead\")\n",
    "while logger.handlers:\n",
    "      logger.handlers.pop()\n",
    "c_handler = logging.StreamHandler()\n",
    "# link handler to logger\n",
    "logger.addHandler(c_handler)\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.propagate = False\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "direct_run makes skip the user inputs\n",
    "'''\n",
    "loading_dir_pre =EEG_sleep_dir(splidle_inc=False)\n",
    "# --------------------------------------------------------------------------\n",
    "#  first assign the i/p and o/p directories\n",
    "# --------------------------------------------------------------------------\n",
    "loading_dir_pre.in_loc = '/Users/anandanadarajn/Documents/.../results_pickles/check_loose_lead/'\n",
    "loading_dir_pre.out_loc ='/Users/anandanadarajn/Documents/.../results_pickles/check_loose_lead/'\n",
    "\n",
    "loading_dir_pre.keep_signature_dic ={}\n",
    "loading_dir_pre.keep_signature_dic['dic']=True\n",
    "loading_dir_pre.keep_signature_dic['evtxt']=True\n",
    "loading_dir_pre.keep_signature_dic['bad_epochs']=True\n",
    "loading_dir_pre.keep_signature_dic['out_loc_outlier']=True\n",
    "loading_dir_pre.keep_signature_dic['sleep_anot']=True\n",
    "loading_dir_pre.keep_signature_dic['MT_spec']=True\n",
    "loading_dir_pre.keep_signature_dic['annota_NREM_REM']=True\n",
    "loading_dir_pre.keep_signature_dic['splidle_inc']=True\n",
    "loading_dir_pre.keep_signature_dic['tex_files']=True\n",
    "\n",
    "loading_dir_pre.save_spindle_loc = True\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# re assign the loading_dir_pre object\n",
    "# --------------------------------------------------------------------------\n",
    "loading_dir_pre.assign_directories()\n",
    "f='edf_name'\n",
    "\n",
    "'''\n",
    "getting user input and call loose-lead detection\n",
    "'''\n",
    "opt_paramters = parameter_assignment()\n",
    "opt_paramters.loading_dir_pre = loading_dir_pre\n",
    "\n",
    "opt_paramters.sep = False\n",
    "\n",
    "opt_paramters.tag='_def'\n",
    "\n",
    "pred_slow_waves = opt_paramters.pred_slow_waves\n",
    "pred_spindles = opt_paramters.pred_spindles \n",
    "\n",
    "T = opt_paramters.T\n",
    "amplitude_high_same_all_age = opt_paramters.amplitude_high_same_all_age\n",
    "avoid_spindle_loc = opt_paramters.avoid_spindle_loc\n",
    "verbose  = opt_paramters.verbose\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# assigning the directories\n",
    "# --------------------------------------------------------------------------\n",
    "in_loc = loading_dir_pre.in_loc\n",
    "# save_converted_index_loc = loading_dir_pre.save_converted_index_loc\n",
    "# out_loc_outlier = loading_dir_pre.out_loc_outlier\n",
    "in_bad_events = loading_dir_pre.bad_events_file_path\n",
    "save_spindle_loc = loading_dir_pre.save_spindle_loc\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "#  if the file not ends with edf add edf extention\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "if in_name_temp.split('.')[-1]!='edf':\n",
    "    in_edf = in_loc + in_name_temp + \".edf\"\n",
    "else:\n",
    "    in_edf = in_loc + in_name_temp \n",
    "    in_name_temp = '.'.join(in_name_temp.split('.')[0:-1])\n",
    "logger.warning('*** filename: %s', in_edf)\n",
    "\n",
    "if len(opt_paramters.tag)>0:\n",
    "    in_name_temp= in_name_temp+opt_paramters.tag\n",
    "\n",
    "epoch_length, line_freq, bandpass_freq, normal_only, notch_freq_essential_checker, amplitude_thres = opt_paramters.preprocess_par()\n",
    "\n",
    "amplitude_thres =2000\n",
    "# --------------------------------------------------------------------------\n",
    "# developments optional to user\n",
    "# --------------------------------------------------------------------------\n",
    "save_events_origin = opt_paramters.save_events_origin\n",
    "sleep_stage_preprocess_origin = opt_paramters.sleep_stage_preprocess_origin\n",
    "\n",
    "os.chdir('/')#to make sure appending paths\n",
    "EEG_root, sleep_stages_or, EEG_channels, Fs, start_time_idx,  sel_index_sl_st, whole_annotations, ev_or = load_root_dataset(in_edf, epoch_length)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# save the events for checking purpose\n",
    "# --------------------------------------------------------------------------\n",
    "if save_events_origin:\n",
    "    np.save(loading_dir_pre.out_loc_NREM_REM+ in_name_temp + \"_sel_index_sl_st\",sel_index_sl_st)\n",
    "    np.save(loading_dir_pre.out_loc_NREM_REM+ in_name_temp + \"_ev_or\",ev_or)\n",
    "    \n",
    "bad_epochs = markBadEpochs(in_edf, in_bad_events, epoch_sec=epoch_length)\n",
    "if loading_dir_pre.keep_signature_dic['bad_epochs']:\n",
    "    np.save(loading_dir_pre.bad_epochs_folder+ in_name_temp + \"_bad_epochs\",bad_epochs)\n",
    "#  make deep copy \n",
    "EEG_root_copy=deepcopy(EEG_root)\n",
    "if avoid_spindle_loc:\n",
    "    sleep_stages_origin =  deepcopy(sleep_stages_or)\n",
    "\n",
    "\n",
    "sleep_stages=  deepcopy(sleep_stages_or)\n",
    "# --------------------------------------------------------------------------\n",
    "# Segment EEG into 30sec epochs, apply notch & band filters, mark bad epochs and normalization\n",
    "# this is preprocessing the EEG signal in time domain and return the preprocessed signal in time domain\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# this will force the events with the channels information\n",
    "#   channel_specific_preprocess=True \n",
    "# if not channel_specific_preprocess just return the epoch status without channel specific information\n",
    "# like nan value, high/lower amplitude etc.\n",
    "# --------------------------------------------------------------------------\n",
    "channel_specific_preprocess = opt_paramters.channel_specific_preprocess\n",
    "# --------------------------------------------------------------------------\n",
    "# EEG_channels extracted from the load_root_dataset\n",
    "# such that filaly the default channels will be endup in\n",
    "# ch_names = ['F3', 'F4', 'C3', 'C4', 'O1', 'O2']\n",
    "# --------------------------------------------------------------------------\n",
    "ch_names = EEG_channels    \n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# in the fuiltertaion process the \n",
    "# EEG_root_copy have higher chance of filetisation\n",
    "#  so keep them in a seperate deep copy is prefered\n",
    "# \n",
    "#  to feed the filterd EEG through the MT-make sure assign this as True\n",
    "# basically the epoches points to the EEG_root_copies location\n",
    "# --------------------------------------------------------------------------\n",
    "filtered_EEG_MT=True\n",
    "epochs, EEG_root_copy, sleep_stages, epoch_start_idx_o, epoch_status, q1,q2,q3, notch_filter_skipped = segment_EEG(EEG_root_copy, \n",
    "                                                                                sleep_stages, \n",
    "                                                                                epoch_length, \n",
    "                                                                                Fs, start_time_idx, \n",
    "                                                                                notch_freq=line_freq, \n",
    "                                                                                bandpass_freq=bandpass_freq, \n",
    "                                                                                amplitude_thres=amplitude_thres, \n",
    "                                                                                channel_specific_preprocess=channel_specific_preprocess,\n",
    "                                                                                ch_names=ch_names,\n",
    "                                                                                bad_epochs=bad_epochs,notch_freq_essential_checker=notch_freq_essential_checker,\n",
    "                                                                                return_filtered_EEG=True,\n",
    "                                                                                verbose=verbose)\n",
    "\n",
    "preprocess_events_to_txt(in_name_temp+'_pre_process.txt',loading_dir_pre.out_loc_txt, epoch_status,  preprocess_txt_only_detected_bad=True)\n",
    "temp= {}\n",
    "temp['Fs']=Fs\n",
    "\n",
    "temp['q1']=np.array(q1)\n",
    "temp['q2']=np.array(q2)\n",
    "temp['q3']=np.array(q3)\n",
    "\n",
    "temp['notch_filter_skipped']=notch_filter_skipped\n",
    "\n",
    "temp['empty_EEG_segs']=False\n",
    "if epochs.shape[0] <= 0:\n",
    "    temp['empty_EEG_segs']=True\n",
    "    raise ValueError('Empty EEG segments')\n",
    "\n",
    "if normal_only:\n",
    "    good_ids = np.where(epoch_status=='normal')[0]\n",
    "    sel_id_name='good_ids'\n",
    "    if len(good_ids)<=300:\n",
    "        temp['less_300']=True\n",
    "    else:\n",
    "        temp['less_300']=False\n",
    "else:\n",
    "    raise Exception(\"need to modify the epoch status to selecting status, sin cethe outlier detection is build based only on normal epoch in mind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60120196",
   "metadata": {},
   "source": [
    "Here we pass the good_ids (annoated as \"normal\" by preprocessing). \n",
    "Then used by spindle_detect_main to extract the spindle/ slow-wave information.\n",
    "Or directly obtain only the continious segmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d650bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "#for the time being only the good ids we can separatly chechk the higher/ lower cropped portions\n",
    "# --------------------------------------------------------------------------\n",
    "sel_ids = good_ids\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "#  When we are avoiding the spindle occuring location\n",
    "#   while creating the spindle location the connious segmentation is done\n",
    "# \n",
    "# --------------------------------------------------------------------------\n",
    "if avoid_spindle_loc:\n",
    "    # --------------------------------------------------------------------------\n",
    "    #  for spindle detect ion we feed the unpreprocessed (not filter applied) the EEG data\n",
    "    # --------------------------------------------------------------------------\n",
    "    data=deepcopy(EEG_root)\n",
    "\n",
    "    # spindle detection intiated \n",
    "    sw_columns_ordered =  ['Start', 'End', 'MidCrossing','Duration', 'NegPeak', 'PosPeak',  'ValNegPeak', 'ValPosPeak', \n",
    "                'PTP', 'Slope', 'Frequency',  'IdxChannel']\n",
    "\n",
    "    sp_columns_ordered =  ['Start', 'End', 'Duration', 'Peak', 'Amplitude', 'RMS', 'AbsPower',\n",
    "            'RelPower', 'Frequency', 'Oscillations', 'Symmetry', 'IdxChannel']\n",
    "    \n",
    "    pred_slow_waves=True\n",
    "    pred_spindles =True\n",
    "    \n",
    "    cont_EEG_segments,start_keys,cont_EEG_segments_np, sp_sw_dic_format =  spindle_detect_main(in_name_temp, sel_ids, start_time_idx,\n",
    "                                        data, sleep_stages_origin, save_spindle_loc, sel_id_name=sel_id_name,\n",
    "            Fs=Fs, epoch_length=epoch_length, window_time=epoch_length, s_loc=0, e_loc=1,\n",
    "            sw_columns_ordered=sw_columns_ordered,sp_columns_ordered=sp_columns_ordered,\n",
    "            pred_slow_waves=pred_slow_waves, pred_spindles =pred_spindles)\n",
    "else:\n",
    "    # --------------------------------------------------------------------------\n",
    "    # to obtain the continious segmentations for the loose lead detection\n",
    "    # \n",
    "    # whether save the continious segments or not\n",
    "    # \n",
    "    # --------------------------------------------------------------------------\n",
    "    save_cont_seg=False\n",
    "    cont_EEG_segments_use =  save_cont_segs(in_name_temp, loading_dir_pre.out_loc_NREM_REM, sel_ids, start_time_idx, Fs,\n",
    "                                            sel_id_name='good_ids', epoch_length=epoch_length,\n",
    "                                            save_cont_seg=save_cont_seg)\n",
    "\n",
    "    start_keys = list(cont_EEG_segments_use.keys())\n",
    "    cont_EEG_segments_np = continious_seg_to_np(cont_EEG_segments_use, start_keys)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e510276",
   "metadata": {},
   "source": [
    "Only use the good_ids (annoated as \"normal\" by preprocessing).\n",
    "Then only the good_ids' signal and sleep stages are used for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a17f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if normal_only:\n",
    "    good_ids = np.where(epoch_status=='normal')[0]\n",
    "    sleep_stages_orgin = deepcopy(sleep_stages)\n",
    "    sleep_stages = sleep_stages[good_ids]\n",
    "\n",
    "    epochs = epochs[good_ids]\n",
    "    try:\n",
    "        epoch_start_idx = epoch_start_idx_o[good_ids]\n",
    "    except:\n",
    "        epoch_start_idx =  np.array(epoch_start_idx_o)[good_ids.astype(int)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b95144",
   "metadata": {},
   "source": [
    "Save the overall exatracted sleep-stages (raw).\n",
    "Note: not only the good_ids' sleep-stages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d194d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# saving the preprocessed sleep-stages\n",
    "# --------------------------------------------------------------------------\n",
    "if sleep_stage_preprocess_origin:\n",
    "    np.save(loading_dir_pre.out_loc_NREM_REM+ in_name_temp + '_sleep_stages_orgin',sleep_stages_orgin)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d846b1bf",
   "metadata": {},
   "source": [
    "## MT-spectral estimation and Correlation retrieval\n",
    "Since the correlation extraction is done after the MT-extraction.\n",
    "\n",
    "The b_val is feed as input to the fuction MT_based_correltion_calc_in_continious_segs.\n",
    "If we do the Fisher-based standardisation (with tanh) on correlations inorder to satisfy the boundry conditions,\n",
    "like correlation (1 or -1), need to be adjusted with small negation or addition with b_val. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23534e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "#this assign values are especillay for correlation based loose lead detection\n",
    "# adjust the boundry values and mapped by tanh\n",
    "# z_transform=True\n",
    "# --------------------------------------------------------------------------\n",
    "b_val=opt_paramters.b_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b5ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# as this functions is limited to 1 sec sliding through the MT-spectrum\n",
    "# as the corrrelation value of the temporal information is obtained in 1 sec resolution can bve later down sampled \n",
    "# like sliding 2 sec by removing the one sample in the middle (kind of downsampling)\n",
    "# \n",
    "# The correltion is calulated bween the given frquency band f_min_interst-f_max_interst\n",
    "# Here we used the bandpassed range to calculate the correltaion\n",
    "#\n",
    "# save_MT_spectrum: will onkygive the spectrum output which can be later used to save\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# either filterd EEG can be fed through the MT-estimation \n",
    "# --------------------------------------------------------------------------\n",
    "if filtered_EEG_MT:\n",
    "    EEG_MT_feed = EEG_root_copy\n",
    "else:\n",
    "    EEG_MT_feed =   EEG_root\n",
    "        \n",
    "# --------------------------------------------------------------------------\n",
    "# to calculate correlation in the db scale or given scale\n",
    "# --------------------------------------------------------------------------\n",
    "db_scale=False\n",
    "correlation_flatten_MT_not_opt, sleep_stages_annot_flatten, MT_spec_not_db = \\\n",
    "                                        MT_based_correltion_calc_in_continious_segs(EEG_MT_feed, sleep_stages, cont_EEG_segments_np, \n",
    "                                        Fs,ch_names, start_time_idx=start_time_idx, T=T, db_scale=db_scale,\n",
    "                                        f_min_interst=bandpass_freq[0], f_max_interst=bandpass_freq[1], \n",
    "                                        window_time=epoch_length, padding=0, sleep_stage_anoot_ext=True,\n",
    "                                        interested_channels_index=[],root_data=True,\n",
    "                                        b_val=b_val,inter_mediate_transform=False, \n",
    "                                        optim_bandwidth=False,\n",
    "                                        save_MT_spectrum=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d47e7a2",
   "metadata": {},
   "source": [
    "## Spindle and MT-coorelatiion one hot encoding\n",
    "Since the spindle information must be incopertaed with the extracted MT-spectrum (and their corresponding obtained correlation).\n",
    "In case if we need to exclude/ include the spindle based analysis later. Such that inorder to connect them together the one hot encoding is used, here the spindles locations are marked with one-hot encoding, and their properties (information) is passed with another variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d28a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# spindle_interest_channel= like if we are only targetting the central channels for the spindle calculation\n",
    "# --------------------------------------------------------------------------\n",
    "if avoid_spindle_loc:\n",
    "    # sp_sw_dic_format_copy =deepcopy(sp_sw_dic_format)\n",
    "    spindle_possible_channels =[]#probabily on C3 like   \n",
    "\n",
    "    spindle_enc, spindle_info_hold =  convert_to_full_one_hot_mapping_based_cont_seg_sp_sw_all_channels(sp_sw_dic_format,\n",
    "                                        sleep_stages_or,cont_EEG_segments_np,Fs, MT_spec_not_db, start_time_idx, ep_length=30,\n",
    "                                        o_p_adjuster=3, boundry_cond_sec_frac=0.5,combine_intersted_channels_to_all=False,\n",
    "                                        ch_names = ch_names, spindle_interest_channel=spindle_possible_channels)\n",
    "    \n",
    "else:\n",
    "    spindle_enc=[]\n",
    "\n",
    "if len(spindle_enc)>0:\n",
    "    in_name_temp = in_name_temp+'_avoid_spindle'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171f820e",
   "metadata": {},
   "source": [
    "## Assigning the hyper-paramters for correlation based loose-lead detection\n",
    "\n",
    "We have the choice to use the distribution or moving window.\n",
    "Any of these methods need the hyper-parameter assignment, for retrive the detect the  outlier segments\n",
    " (possible potential loose-leads segments).\n",
    "\n",
    "### Hyper parameters for only Distribution based \n",
    "tail_check_bin, GMM_based,    factor_check, threh_prob, outlier_basic_con\n",
    "### Hyper parameters for only Moving window based \n",
    " sep, global_check, only_good_points, sorted_median_cont_grp_comp_sort_median_cond, sorted_median_cont_grp_comp_sort_max_cond, sorted_median_cont_grp_comp_sort_quan_cond \n",
    "\n",
    "\n",
    "Since the ``methodology_related_paramaters_for_outlier_detection()'' function retrive all the hyperparamters for both methods (like distribution, moving window). The user can safely ignore the unwanted hyper-parameters.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b60288",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail_check_bin, GMM_based,    factor_check, threh_prob, outlier_basic_con,\\\n",
    "            moving_window_based, moving_window_size, th_fact,\\\n",
    "            sep, global_check, only_good_points,\\\n",
    "            sorted_median_cont_grp_comp_sort_median_cond, sorted_median_cont_grp_comp_sort_max_cond, sorted_median_cont_grp_comp_sort_quan_cond,\\\n",
    "            cont_seg_wise, cont_threh, threh_prob_artf_cont_seg, \\\n",
    "            with_conv,thresh_min_conv,thresh_in_sec,outlier_presene_con_lenth_th, \\\n",
    "            with_fill_period=opt_paramters.methodology_related_paramaters_for_outlier_detection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
